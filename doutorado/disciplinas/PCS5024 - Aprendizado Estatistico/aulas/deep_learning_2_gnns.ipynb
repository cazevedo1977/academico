{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2054b02",
   "metadata": {},
   "source": [
    "# PCS5024 - Aprendizado Estat√≠stico - Statistical Learning - 2023/1\n",
    "### Professors: \n",
    "### Anna Helena Reali Costa (anna.reali@usp.br)\n",
    "### Fabio G. Cozman (fgcozman@usp.br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0b447ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet torch_geometric torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e511eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d362d-d6b6-427d-bdab-ccd648bd94a7",
   "metadata": {},
   "source": [
    "# Graph Neural Networks\n",
    "\n",
    "Graph Neural Networks (GNNs) are a class of deep learning models designed to work with graph-structured data. They have gained significant attention in recent years due to their ability to model complex relationships and patterns in a variety of domains, including social networks, molecular structures, and recommendation systems, among others.\n",
    "\n",
    "GNNs can be considered a generalization of CNNs (grid graph), RNNs (line graph) and Transformers (fully connected graph)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc0c924",
   "metadata": {},
   "source": [
    "<img src='https://miro.medium.com/v2/resize:fit:720/format:webp/1*e8xtqXuqNCBWhzdbF7krtA.png'  width=\"60%\" height=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b8445",
   "metadata": {},
   "source": [
    "The main concept in GNNs is the message passing mechanism. \n",
    "\n",
    "<img src='https://drive.google.com/uc?id=14GojFf-UdTkBtlmKpLmBaHO5FpIwadq1'  width=\"40%\" height=\"40%\">\n",
    "\n",
    "Let's break it down into its components!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2e1825",
   "metadata": {},
   "source": [
    "### The message function $\\phi$\n",
    "<img src='https://drive.google.com/uc?id=1OOytQ9n9yf81-lQHXk0Zqnm_NczvxFc7'  width=\"20%\" height=\"20%\">\n",
    "\n",
    "Creates a vector representation for each edge that represents a **message** sent by node j to node i.\n",
    "\n",
    "$\\phi$ can be any differentiable function, so it can be trained through SGD. A common choice are MLPs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc025be3",
   "metadata": {},
   "source": [
    "### The permutation invariant aggregation $\\bigoplus$\n",
    "<img src='https://drive.google.com/uc?id=1OnO1UQqfa8wbm1ozi9oYuck1w8F-MQIg'  width=\"6%\" height=\"6%\">\n",
    "\n",
    "Aggregate all messages from all neighbours into a single vector representation.\n",
    "\n",
    "$\\bigoplus$ can be any permutation invariant operation since permutation of neighbours produce isomorphic graphs. Examples are sum, mean, max and min."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb42b1f",
   "metadata": {},
   "source": [
    "### The update function $\\gamma$\n",
    "<img src='https://drive.google.com/uc?id=1k7KQl4CNvqVpZ0K1dMIXfJJpYfdnU5aU'  width=\"40%\" height=\"40%\">\n",
    "\n",
    "Updates the target node's representation based on the aggregated message from neighbours.\n",
    "\n",
    "Many GNNs architectures utilize a $\\phi$ function with self-loops instead. It reduces the representation power, but also reduces training complexity.\n",
    "\n",
    "Let's see an example of Node Classification on the Cora Dataset using PyTorch Geometric.\n",
    "\n",
    "The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words.\n",
    "\n",
    "https://relational.fit.cvut.cz/dataset/CORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d0a1f0-48a4-4d7a-b7aa-00a48330f4d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root=\"/tmp/Cora\", name=\"Cora\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e839c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,hidden_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_size)\n",
    "        self.conv2 = GCNConv(hidden_size, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e882fb7e-942f-4f5b-a4e9-c79c625ed358",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hidden_size = 100\n",
    "model = GCN(hidden_size).to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde96cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8120\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f\"Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9afa09",
   "metadata": {},
   "source": [
    "More information about GNNs and other geometric generalizations in Deep Learning can be found in:\n",
    "Bronstein et al. - https://arxiv.org/abs/2104.13478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3898677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cashme] *",
   "language": "python",
   "name": "conda-env-cashme-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
