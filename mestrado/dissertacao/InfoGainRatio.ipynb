{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information gain is a splitting criterion that comes from information theory. It uses information entropy as the impurity function. \n",
    "\n",
    "O objetivo aqui √© discorrer sobre os conceitos e implementa√ß√µes dos m√©todos de medi√ß√£o dos indicadores de impureza de uma amostra de dados, especificamente: \n",
    "- Entropy\n",
    "- Gini index\n",
    "- Caio Azevedo, May 22 2021\n",
    "\n",
    "Principais refer√™ncias:\n",
    "- ref. https://www.featureranking.com/tutorials/machine-learning-tutorials/information-gain-computation/\n",
    "- ref. https://machinelearningmastery.com/information-gain-and-mutual-information/\n",
    "- ref. https://sites.math.washington.edu/~morrow/336_15/papers/lev.pdf\n",
    "- ref. https://victorzhou.com/blog/information-gain/ (muito did√°tico)\n",
    "- ref. https://www.analyticssteps.com/blogs/what-gini-index-and-information-gain-decision-trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeira implementa√ß√£o usando apenas numpy e pandas\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     apple\n",
      "1     apple\n",
      "2     apple\n",
      "3    orange\n",
      "4    orange\n",
      "5    banana\n",
      "6    banana\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "lst = ['apple']*3 + ['orange']*2 + ['banana']*2\n",
    "fruits = pd.Series(lst)\n",
    "print(fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apple     0.428571\n",
       "banana    0.285714\n",
       "orange    0.285714\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computa a frequencia relativa para cada fruta na lista, que pode ser interpretada com a distribui√ß√£o de probabilidade das frutas.\n",
    "# Here is the relative frequency of each fruit in the basket, which can be considered as the probability distribution of the fruits.\n",
    "probs = fruits.value_counts(normalize=True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42857142857142855, 0.2857142857142857, 0.2857142857142857]\n"
     ]
    }
   ],
   "source": [
    "probs_by_hand = [3/7, 2/7, 2/7]\n",
    "print(probs_by_hand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a probability distribution ùëÉ = (ùëù1, ùëù2, . . , ùëùùëõ), where ùëùùëñ is the probability that a point is in the subset ùê∑ùëñ of a dataset ùê∑, we define the entropy ùêª:\n",
    "Recall that Shannon's model defines entropy as\n",
    "$$H(P) = -\\sum_i^l{p_i} + log_2(p_i)$$\n",
    "The idea with entropy is that the more heterogenous and impure a feature is, the higher the entropy. Conversely, the more homogenous and pure a feature is, the lower the entropy. The following calculation shows how impurity of this fruit basket can be computed using the entropy criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5566567074628228"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy = -1 * np.sum(probs * np.log2(probs))\n",
    "entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gini impurity index is defined as follows:\n",
    "$$Gini(x) = 1-\\sum_i^l{p_i}^2$$\n",
    "The idea with Gini index is the same as in entropy in the sense that the more heterogenous and impure a feature is, the higher the Gini index. A nice property of the Gini index is that it is always between 0 and 1, and this may make it easier to compare Gini indices across different features. The impurity of our fruit basket using Gini index is calculated as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.653061224489796"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_index = 1 - np.sum(np.square(probs))\n",
    "gini_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         apple\n",
      "1        orange\n",
      "2        banana\n",
      "3         mango\n",
      "4     blueberry\n",
      "5    watermelon\n",
      "6          pear\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "watermelon    0.142857\n",
       "blueberry     0.142857\n",
       "banana        0.142857\n",
       "mango         0.142857\n",
       "apple         0.142857\n",
       "pear          0.142857\n",
       "orange        0.142857\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In comparison, let's compute impurity of another fruit basket with 7 different fruits with equal frequency.\n",
    "lst2 = ['apple', 'orange', 'banana', 'mango', 'blueberry', 'watermelon', 'pear']\n",
    "fruits2 = pd.Series(lst2)\n",
    "print(fruits2)\n",
    "probs2 = fruits2.value_counts(normalize=True)\n",
    "probs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.807354922057604"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy = -1 * np.sum(np.log2(probs2) * probs2)\n",
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428572"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_index = 1 - np.sum(np.square(probs2))\n",
    "gini_index\n",
    "#As expected, both entropy and Gini index of the second fruit basket is higher than those of the first fruit basket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stream</th>\n",
       "      <th>slope</th>\n",
       "      <th>elevation</th>\n",
       "      <th>vegetation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>steep</td>\n",
       "      <td>high</td>\n",
       "      <td>chapparal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>moderate</td>\n",
       "      <td>low</td>\n",
       "      <td>riparian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>steep</td>\n",
       "      <td>medium</td>\n",
       "      <td>riparian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>steep</td>\n",
       "      <td>medium</td>\n",
       "      <td>chapparal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>flat</td>\n",
       "      <td>high</td>\n",
       "      <td>conifer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>steep</td>\n",
       "      <td>highest</td>\n",
       "      <td>conifer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>steep</td>\n",
       "      <td>high</td>\n",
       "      <td>chapparal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stream     slope elevation vegetation\n",
       "0   False     steep      high  chapparal\n",
       "1    True  moderate       low   riparian\n",
       "2    True     steep    medium   riparian\n",
       "3   False     steep    medium  chapparal\n",
       "4   False      flat      high    conifer\n",
       "5    True     steep   highest    conifer\n",
       "6    True     steep      high  chapparal"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Agora vamos calcular os ind√≠ces de cada feature em um dataframe em rela√ß√£o a um target.\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# if you run into any SSL certification issues, \n",
    "# you may need to run the following command for a Mac OS installation.\n",
    "# $/Applications/Python\\ 3.6/Install\\ Certificates.command\n",
    "\n",
    "# how to read a csv file from a github account\n",
    "df_url = 'https://raw.githubusercontent.com/cazevedo1977/datasets_2_ml/main/vegetation.csv'\n",
    "\n",
    "url_content = requests.get(df_url).content\n",
    "# print(url_content)\n",
    "df = pd.read_csv(io.StringIO(url_content.decode('utf-8')))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_impurity(feature, impurity_criterion):\n",
    "    \"\"\"\n",
    "    This function calculates impurity of a feature.\n",
    "    Supported impurity criteria: 'entropy', 'gini'\n",
    "    input: feature (this needs to be a Pandas series)\n",
    "    output: feature impurity\n",
    "    \"\"\"\n",
    "    probs = feature.value_counts(normalize=True)\n",
    "    \n",
    "    if impurity_criterion == 'entropy':\n",
    "        impurity = -1 * np.sum(probs * np.log2(probs))\n",
    "    elif impurity_criterion == 'gini':\n",
    "        impurity = 1 - np.sum(np.square(probs))\n",
    "    else:\n",
    "        raise ValueError('Unknown impurity criterion')\n",
    "        \n",
    "    return(round(impurity, 3))\n",
    "\n",
    "# let's do two quick examples.\n",
    "#print('impurity using entropy:', compute_impurity(fruits, 'entropy'))\n",
    "#print('impurity using gini index:', compute_impurity(fruits, 'gini'))\n",
    "# how to test for an incorrect compute_impurity_criterion value:\n",
    "# print('impurity using gini index:', compute_impurity(df['stream'], 'foo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.557"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's calculate entropy of the target feature \"vegetation\" using our new function.\n",
    "target_entropy = compute_impurity(df['vegetation'], 'entropy')\n",
    "target_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the information gain for splitting based on a descriptive feature to figure out the best feature to split on. For this task, we do the following:\n",
    "- 1. Compute impurity of the target feature 'vegetation' (using either entropy or gini index).\n",
    "- 2. Partition the dataset based on unique values of the descriptive feature.\n",
    "- 3. Compute impurity (entropy) for each partition.\n",
    "- 4. Compute the remaining impurity as the weighted sum of impurity of each partition.\n",
    "- 5. Compute the information gain as the difference between the impurity of the target feature and the remaining impurity.\n",
    "\n",
    "In case of impurity being entropy, it is possible to compute information gain ratio as well. If so, we do the following:\n",
    "- 6. Compute the split_information defined by:\n",
    "- 7. Divide information gain by the split_information\n",
    "\n",
    "We will define another function to achieve this, called comp_feature_information_gain(). As an example, let's have a look at the levels of the \"elevation\" feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high       3\n",
       "medium     2\n",
       "highest    1\n",
       "low        1\n",
       "Name: elevation, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['elevation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level name: high\n",
      "corresponding data partition:\n",
      "   stream  slope elevation vegetation\n",
      "0   False  steep      high  chapparal\n",
      "4   False   flat      high    conifer\n",
      "6    True  steep      high  chapparal\n",
      "partition target feature impurity: 0.918\n",
      "partition weight: 3/7\n",
      "====================\n",
      "level name: low\n",
      "corresponding data partition:\n",
      "   stream     slope elevation vegetation\n",
      "1    True  moderate       low   riparian\n",
      "partition target feature impurity: -0.0\n",
      "partition weight: 1/7\n",
      "====================\n",
      "level name: medium\n",
      "corresponding data partition:\n",
      "   stream  slope elevation vegetation\n",
      "2    True  steep    medium   riparian\n",
      "3   False  steep    medium  chapparal\n",
      "partition target feature impurity: 1.0\n",
      "partition weight: 2/7\n",
      "====================\n",
      "level name: highest\n",
      "corresponding data partition:\n",
      "   stream  slope elevation vegetation\n",
      "5    True  steep   highest    conifer\n",
      "partition target feature impurity: -0.0\n",
      "partition weight: 1/7\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "##### Let's see how the partitions look like for this feature and what the corresponding calculations are using the entropy split criterion.\n",
    "for level in df['elevation'].unique():\n",
    "    print('level name:', level)\n",
    "    df_feature_level = df[df['elevation'] == level]\n",
    "    print('corresponding data partition:')\n",
    "    print(df_feature_level)\n",
    "    print('partition target feature impurity:', compute_impurity(df_feature_level['vegetation'], 'entropy'))\n",
    "    print('partition weight:', str(len(df_feature_level)) + '/' + str(len(df)))\n",
    "    print('====================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is that, for each one of the 4 data partitions above,\n",
    "- 1. We compute their impurity with respect to the target feature as a stand-alone dataset.\n",
    "- 2. We weigh these impurities with the relative number of observations in each partition. The relative number of observations is calculated as the number of observations in the partition divided by the total number of observations in the entire dataset. For instance, the weight of the first partition is 3/7.\n",
    "- 3. We add up these weighted impurities and call it the remaining impurity for this feature.\n",
    "\n",
    "For instance, remaining impurity as measured by entropy for the elevation feature is 0.918 x (3/7) + 1.0 x (2/7) = 0.679. Information gain is then calculated as 1.557 - 0.679 = 0.878. Now we are ready to define our function. There is a bit of coding in here, but we can assure you that trying to figure out how things work in here will be rewarding to improve your Python programming skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_colors import *\n",
    "def comp_feature_information_gain(df, target, descriptive_feature, split_criterion):\n",
    "    \"\"\"\n",
    "    This function calculates information gain for splitting on \n",
    "    a particular descriptive feature for a given dataset\n",
    "    and a given impurity criteria.\n",
    "    Supported split criterion: 'entropy', 'gini'\n",
    "    \"\"\"\n",
    "    \n",
    "    print('target feature:', target)\n",
    "    print('descriptive_feature:', descriptive_feature)\n",
    "    print('split criterion:', split_criterion)\n",
    "            \n",
    "    target_entropy = compute_impurity(df[target], split_criterion)\n",
    "    print('target entropy:', target_entropy)\n",
    "\n",
    "    # we define two lists below:\n",
    "    # entropy_list to store the entropy of each partition\n",
    "    # weight_list to store the relative number of observations in each partition\n",
    "    entropy_list = list()\n",
    "    weight_list = list()\n",
    "        \n",
    "    # loop over each level of the descriptive feature\n",
    "    # to partition the dataset with respect to that level\n",
    "    # and compute the entropy and the weight of the level's partition\n",
    "    for level in df[descriptive_feature].unique():\n",
    "        df_feature_level = df[df[descriptive_feature] == level]\n",
    "        entropy_level = compute_impurity(df_feature_level[target], split_criterion)\n",
    "        entropy_list.append(round(entropy_level, 3))\n",
    "        weight_level = len(df_feature_level) / len(df)\n",
    "        weight_list.append(round(weight_level, 3))\n",
    "       \n",
    "    print('impurity of partitions:', entropy_list)\n",
    "    print('weights of partitions:', weight_list)\n",
    "    \n",
    "    feature_remaining_impurity = np.sum(np.array(entropy_list) * np.array(weight_list))\n",
    "    print('remaining impurity:', feature_remaining_impurity)\n",
    "    \n",
    "    information_gain = target_entropy - feature_remaining_impurity\n",
    "    print('information gain:', yellow(\"\\033[1m\" +  str(information_gain) + \"\\033[1m\"))\n",
    "\n",
    "    if split_criterion == 'entropy':\n",
    "        split_info = compute_impurity(df[descriptive_feature], split_criterion)\n",
    "        information_gain_ratio = information_gain / split_info\n",
    "        print('split info:', split_info)\n",
    "        print('information gain ratio:', green(\"\\033[1m\" +  str(information_gain_ratio) + \"\\033[1m\"))\n",
    "    \n",
    "    print('====================')\n",
    "\n",
    "    return(information_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target feature: vegetation\n",
      "descriptive_feature: stream\n",
      "split criterion: entropy\n",
      "target entropy: 1.557\n",
      "impurity of partitions: [0.918, 1.5]\n",
      "weights of partitions: [0.429, 0.571]\n",
      "remaining impurity: 1.250322\n",
      "information gain: \u001b[33m\u001b[1m0.306678\u001b[1m\u001b[0m\n",
      "split info: 0.985\n",
      "information gain ratio: \u001b[32m\u001b[1m0.3113482233502538\u001b[1m\u001b[0m\n",
      "====================\n",
      "target feature: vegetation\n",
      "descriptive_feature: slope\n",
      "split criterion: entropy\n",
      "target entropy: 1.557\n",
      "impurity of partitions: [1.371, -0.0, -0.0]\n",
      "weights of partitions: [0.714, 0.143, 0.143]\n",
      "remaining impurity: 0.9788939999999999\n",
      "information gain: \u001b[33m\u001b[1m0.578106\u001b[1m\u001b[0m\n",
      "split info: 1.149\n",
      "information gain ratio: \u001b[32m\u001b[1m0.5031383812010444\u001b[1m\u001b[0m\n",
      "====================\n",
      "target feature: vegetation\n",
      "descriptive_feature: elevation\n",
      "split criterion: entropy\n",
      "target entropy: 1.557\n",
      "impurity of partitions: [0.918, -0.0, 1.0, -0.0]\n",
      "weights of partitions: [0.429, 0.143, 0.286, 0.143]\n",
      "remaining impurity: 0.6798219999999999\n",
      "information gain: \u001b[33m\u001b[1m0.877178\u001b[1m\u001b[0m\n",
      "split info: 1.842\n",
      "information gain ratio: \u001b[32m\u001b[1m0.47620955483170463\u001b[1m\u001b[0m\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "#Now that our function has been defined, we will call it for each descriptive feature in the dataset. First let's call it using the entropy split criteria.\n",
    "split_criterion = 'entropy'\n",
    "for feature in df.drop(columns='vegetation').columns:\n",
    "    feature_info_gain = comp_feature_information_gain(df, 'vegetation', feature, split_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's call it using the gini index split criteria.\n",
    "#split_criteria = 'gini'\n",
    "#for feature in df.drop(columns='vegetation').columns:\n",
    "#    feature_info_gain = comp_feature_information_gain(df, 'vegetation', feature, split_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-30-105066e0dde9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-30-105066e0dde9>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    We observe that, with both the entropy and gini index split criteria, the highest information gain occurs with the \"elevation\" feature. This is the for the split at the root node of the corresponding decision tree. In subsequent splits, the above procedure is repeated with the subset of the entire dataset in the current branch until the termination condition is reached.\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "We observe that, with both the entropy and gini index split criteria, the highest information gain occurs with the \"elevation\" feature. This is the for the split at the root node of the corresponding decision tree. In subsequent splits, the above procedure is repeated with the subset of the entire dataset in the current branch until the termination condition is reached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainy</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainy</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rainy</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>overcast</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sunny</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sunny</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rainy</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sunny</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>overcast</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rainy</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     outlook temperature humidity   wind play\n",
       "0      sunny         hot     high  False   no\n",
       "1      sunny         hot     high   True   no\n",
       "2   overcast         hot     high  False  yes\n",
       "3      rainy        mild     high  False  yes\n",
       "4      rainy        cool   normal  False  yes\n",
       "5      rainy        cool   normal   True   no\n",
       "6   overcast        cool   normal   True  yes\n",
       "7      sunny        mild     high  False   no\n",
       "8      sunny        cool   normal  False  yes\n",
       "9      rainy        mild   normal  False  yes\n",
       "10     sunny        mild   normal   True  yes\n",
       "11  overcast        mild     high   True  yes\n",
       "12  overcast         hot   normal  False  yes\n",
       "13     rainy        mild     high   True   no"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testando outro dataset did√°tico\n",
    "#ref. https://machinewithdata.com/2020/06/17/deriving-decision-tree-using-entropy-id3-approach/\n",
    "#ref. https://machinewithdata.com/2018/07/10/how-to-calculate-gain-ratio/\n",
    "df_url = 'https://raw.githubusercontent.com/cazevedo1977/datasets_2_ml/main/playornot2play.csv'\n",
    "\n",
    "url_content = requests.get(df_url).content\n",
    "# print(url_content)\n",
    "df = pd.read_csv(io.StringIO(url_content.decode('utf-8')))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level name: False\n",
      "corresponding data partition:\n",
      "     outlook temperature humidity   wind play\n",
      "0      sunny         hot     high  False   no\n",
      "2   overcast         hot     high  False  yes\n",
      "3      rainy        mild     high  False  yes\n",
      "4      rainy        cool   normal  False  yes\n",
      "7      sunny        mild     high  False   no\n",
      "8      sunny        cool   normal  False  yes\n",
      "9      rainy        mild   normal  False  yes\n",
      "12  overcast         hot   normal  False  yes\n",
      "partition target feature impurity: 0.811\n",
      "partition weight: 8/14\n",
      "====================\n",
      "level name: True\n",
      "corresponding data partition:\n",
      "     outlook temperature humidity  wind play\n",
      "1      sunny         hot     high  True   no\n",
      "5      rainy        cool   normal  True   no\n",
      "6   overcast        cool   normal  True  yes\n",
      "10     sunny        mild   normal  True  yes\n",
      "11  overcast        mild     high  True  yes\n",
      "13     rainy        mild     high  True   no\n",
      "partition target feature impurity: 1.0\n",
      "partition weight: 6/14\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "##### Let's see how the partitions look like for this feature and what the corresponding calculations are using the entropy split criterion.\n",
    "for level in df['wind'].unique():\n",
    "    print('level name:', level)\n",
    "    df_feature_level = df[df['wind'] == level]\n",
    "    print('corresponding data partition:')\n",
    "    print(df_feature_level)\n",
    "    print('partition target feature impurity:', compute_impurity(df_feature_level['play'], 'entropy'))\n",
    "    print('partition weight:', str(len(df_feature_level)) + '/' + str(len(df)))\n",
    "    print('====================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target feature: play\n",
      "descriptive_feature: outlook\n",
      "split criterion: entropy\n",
      "target entropy: 0.94\n",
      "impurity of partitions: [0.971, -0.0, 0.971]\n",
      "weights of partitions: [0.357, 0.286, 0.357]\n",
      "remaining impurity: 0.693294\n",
      "information gain: \u001b[33m\u001b[1m0.24670599999999998\u001b[1m\u001b[0m\n",
      "split info: 1.577\n",
      "information gain ratio: \u001b[32m\u001b[1m0.15644007609384908\u001b[1m\u001b[0m\n",
      "====================\n",
      "target feature: play\n",
      "descriptive_feature: temperature\n",
      "split criterion: entropy\n",
      "target entropy: 0.94\n",
      "impurity of partitions: [1.0, 0.918, 0.811]\n",
      "weights of partitions: [0.286, 0.429, 0.286]\n",
      "remaining impurity: 0.9117679999999999\n",
      "information gain: \u001b[33m\u001b[1m0.028232000000000035\u001b[1m\u001b[0m\n",
      "split info: 1.557\n",
      "information gain ratio: \u001b[32m\u001b[1m0.018132305716120768\u001b[1m\u001b[0m\n",
      "====================\n",
      "target feature: play\n",
      "descriptive_feature: humidity\n",
      "split criterion: entropy\n",
      "target entropy: 0.94\n",
      "impurity of partitions: [0.985, 0.592]\n",
      "weights of partitions: [0.5, 0.5]\n",
      "remaining impurity: 0.7885\n",
      "information gain: \u001b[33m\u001b[1m0.15149999999999997\u001b[1m\u001b[0m\n",
      "split info: 1.0\n",
      "information gain ratio: \u001b[32m\u001b[1m0.15149999999999997\u001b[1m\u001b[0m\n",
      "====================\n",
      "target feature: play\n",
      "descriptive_feature: wind\n",
      "split criterion: entropy\n",
      "target entropy: 0.94\n",
      "impurity of partitions: [0.811, 1.0]\n",
      "weights of partitions: [0.571, 0.429]\n",
      "remaining impurity: 0.8920809999999999\n",
      "information gain: \u001b[33m\u001b[1m0.047919000000000045\u001b[1m\u001b[0m\n",
      "split info: 0.985\n",
      "information gain ratio: \u001b[32m\u001b[1m0.04864873096446705\u001b[1m\u001b[0m\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "#Now that our function has been defined, we will call it for each descriptive feature in the dataset. First let's call it using the entropy split criteria.\n",
    "split_criterion = 'entropy'\n",
    "for feature in df.drop(columns='play').columns:\n",
    "    feature_info_gain = comp_feature_information_gain(df, 'play', feature, split_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agora fazendo uso da lib info_gain\n",
    "from info_gain import info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'vegetation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Caio\\Miniconda3\\envs\\cashme\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'vegetation'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-2a258fec28ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mig\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0minfo_gain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo_gain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vegetation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'elevation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0miv\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0minfo_gain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintrinsic_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vegetation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'elevation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0migr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfo_gain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo_gain_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vegetation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'elevation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# que √© o mesmo que ig/iv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0migr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mig\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0miv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Caio\\Miniconda3\\envs\\cashme\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Caio\\Miniconda3\\envs\\cashme\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'vegetation'"
     ]
    }
   ],
   "source": [
    "ig  = info_gain.info_gain(df['vegetation'], df['elevation'])\n",
    "iv  = info_gain.intrinsic_value(df['vegetation'], df['elevation'])\n",
    "igr = info_gain.info_gain_ratio(df['vegetation'], df['elevation']) # que √© o mesmo que ig/iv\n",
    "print(ig, iv, igr,ig/iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'vegetation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Caio\\Miniconda3\\envs\\cashme\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'vegetation'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-1726ed769279>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mig\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0minfo_gain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo_gain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vegetation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'slope'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0miv\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0minfo_gain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintrinsic_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vegetation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'slope'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0migr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfo_gain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo_gain_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vegetation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'slope'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0migr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Caio\\Miniconda3\\envs\\cashme\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Caio\\Miniconda3\\envs\\cashme\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'vegetation'"
     ]
    }
   ],
   "source": [
    "ig  = info_gain.info_gain(df['vegetation'], df['slope'])\n",
    "iv  = info_gain.intrinsic_value(df['vegetation'], df['slope'])\n",
    "igr = info_gain.info_gain_ratio(df['vegetation'], df['slope'])\n",
    "print(ig, iv, igr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'vegetation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Caio\\Miniconda3\\envs\\cashme\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'vegetation'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-cb5102bfabc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mig\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0minfo_gain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo_gain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vegetation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stream'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0miv\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0minfo_gain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintrinsic_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vegetation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stream'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0migr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfo_gain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo_gain_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vegetation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stream'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0migr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Caio\\Miniconda3\\envs\\cashme\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Caio\\Miniconda3\\envs\\cashme\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'vegetation'"
     ]
    }
   ],
   "source": [
    "ig  = info_gain.info_gain(df['vegetation'], df['stream'])\n",
    "iv  = info_gain.intrinsic_value(df['vegetation'], df['stream'])\n",
    "igr = info_gain.info_gain_ratio(df['vegetation'], df['stream'])\n",
    "print(ig, iv, igr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando outro conjunto de dados para confrontar as duas implementa√ß√µes\n",
    "produce = ['apple', 'apple', 'apple', 'strawberry', 'eggplant']\n",
    "fruit   = [ True  ,  True  ,  True  ,  True       ,  False    ]\n",
    "colour  = ['green', 'green', 'red'  , 'red'       , 'purple'  ]\n",
    "ig  = info_gain.info_gain(fruit, colour)\n",
    "iv  = info_gain.intrinsic_value(fruit, colour)\n",
    "igr = info_gain.info_gain_ratio(fruit, colour)\n",
    "print(ig, iv, igr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig  = info_gain.info_gain(fruit, produce)\n",
    "iv  = info_gain.intrinsic_value(fruit, produce)\n",
    "igr = info_gain.info_gain_ratio(fruit, produce)\n",
    "print(ig, iv, igr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(list(zip(fruit,colour,produce)),columns = ['fruit','colour','produce'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_criteria = 'entropy'\n",
    "for feature in df2.drop(columns='fruit').columns:\n",
    "    feature_info_gain = comp_feature_information_gain(df2, 'fruit', feature, split_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
